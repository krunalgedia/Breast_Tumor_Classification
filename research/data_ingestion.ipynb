{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81f9c32-8cb9-43cd-b3aa-c93fef2f824d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kbged\\\\Downloads\\\\mlprojects\\\\Breast_Tumor_Classification\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4904fcc2-7f34-4786-9e87-3768dc347284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kbged\\\\Downloads\\\\mlprojects\\\\Breast_Tumor_Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467e6c6-f3d3-4cce-9ad0-11a4f2b901a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a445b8a2-e588-4f89-af7b-f3055c59a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39bb7d6f-6acd-42d8-8fb9-70be4799c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tumorClassify.constants import *\n",
    "from tumorClassify.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbbab18-cd81-45ce-98de-7ec3b7e5c4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('src/tumorClassify/config/config.yaml')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ac3d2d-0b6b-4f63-aa4a-2d40eb32bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                config_filepath = CONFIG_FILE_PATH,\n",
    "                params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1367b3-9a3a-46ed-b2c6-00df704c9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from tumorClassify import logger\n",
    "from tumorClassify.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92c315d-e8cd-459a-ab4f-3b207e905508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        if os.path.exists(self.config.local_data_file):\n",
    "            os.remove(self.config.local_data_file)\n",
    "        try:\n",
    "            subprocess.run(['curl','-L','-o', self.config.local_data_file, self.config.source_URL], check=True)\n",
    "            logger.info(f\"File downloaded and saved as: {self.config.local_data_file}\")\n",
    "            \n",
    "            #logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"Failed to download file at . Error: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to download file: {e}\")\n",
    "            #print()\n",
    "    \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        try:\n",
    "        #    unzip_path = self.config.unzip_dir\n",
    "        #    os.makedirs(unzip_path, exist_ok=True)\n",
    "        #    with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "        #        zip_ref.extractall(unzip_path)\n",
    "        #except Exception as e:\n",
    "        #    logger.error(f'Failed to unzip {self.config.local_data_file} at {unzip_path}')\n",
    "\n",
    "            unzip_path = self.config.unzip_dir\n",
    "            os.makedirs(unzip_path, exist_ok=True)\n",
    "\n",
    "            # Extract the zip file\n",
    "            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(unzip_path)\n",
    "\n",
    "            # Find the name of the extracted folder\n",
    "            extracted_folder_name = None\n",
    "            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "                extracted_folder_name = zip_ref.namelist()[0].split('/')[0]\n",
    "\n",
    "            # Define the full paths for the extracted folder and target folder\n",
    "            extracted_folder_path = os.path.join(unzip_path, extracted_folder_name)\n",
    "            target_folder_path = os.path.join(unzip_path, 'data')\n",
    "\n",
    "            # Rename the extracted folder to 'data'\n",
    "            if os.path.exists(extracted_folder_path):\n",
    "                if os.path.exists(target_folder_path):\n",
    "                    shutil.rmtree(target_folder_path)\n",
    "                os.rename(extracted_folder_path, target_folder_path)\n",
    "                logger.info(f\"Renamed folder '{extracted_folder_name}' to 'data'\")\n",
    "            else:\n",
    "                logger.error(f\"Extracted folder '{extracted_folder_name}' does not exist in the specified path\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Failed to unzip {self.config.local_data_file} at {unzip_path}: {e}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ff7925-ee21-460b-8af3-cf83dd5de8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-13 17:01:05\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcommon.py:26\u001b[0m | \u001b[1myaml file: src\\tumorClassify\\config\\config.yaml loaded successfully\u001b[0m\n",
      "\u001b[32m2024-07-13 17:01:05\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcommon.py:26\u001b[0m | \u001b[1myaml file: params.yaml loaded successfully\u001b[0m\n",
      "\u001b[32m2024-07-13 17:01:05\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcommon.py:49\u001b[0m | \u001b[1mDirectory already exists at: artifacts\u001b[0m\n",
      "\u001b[32m2024-07-13 17:01:05\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[36mcommon.py:49\u001b[0m | \u001b[1mDirectory already exists at: artifacts/data_ingestion\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     data_ingestion_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_data_ingestion_config()\n\u001b[0;32m      4\u001b[0m     data_ingestion \u001b[38;5;241m=\u001b[39m DataIngestion(config\u001b[38;5;241m=\u001b[39mdata_ingestion_config)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mdata_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     data_ingestion\u001b[38;5;241m.\u001b[39mextract_zip_file()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mDataIngestion.download_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlocal_data_file)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-L\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-o\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_data_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_URL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile downloaded and saved as: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlocal_data_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#logger.info(f\"{filename} download! with following info: \\n{headers}\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tumormlflow\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tumormlflow\\lib\\subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tumormlflow\\lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\tumormlflow\\lib\\subprocess.py:1506\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     timeout_millis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e98378b-6c19-48e8-bb26-c3c3899d9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion.extract_zip_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a856714-9543-4ead-ad12-35c7b1ede4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace4934-eaa5-4dec-8242-cb6edf53c650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2654e7d-c0b4-44c3-b8dd-db8e59dcb54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "data_ingestion.config.source_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5982d88-d8b8-4c70-8677-e11640976c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('artifacts/data_ingestion/data.zip',\n",
       " <http.client.HTTPMessage at 0x217299da750>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.urlretrieve(\n",
    "    url=data_ingestion.config.source_URL,\n",
    "    filename=data_ingestion.config.local_data_file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329a2bc-68aa-45a5-88cf-1a11527ae04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.dropbox.com/scl/fi/gkx3j9gk3eg45c2mjyf1s/data_doc_classify.zip?rlkey=mw2iuc5ha4bzy5u3hx0unr603&dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f488d5a7-7459-4d2c-a666-bc5d82b9c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_doc_classify.zip?rlkey=mw2iuc5ha4bzy5u3hx0unr603&dl=0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(data_ingestion.config.source_URL)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "500bee15-868f-4540-b0d1-9f7e4c14d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get(dataingestion.config.source_URL)\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "response = requests.get(data_ingestion.config.source_URL, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(data_ingestion.config.local_data_file, 'wb') as file:\n",
    "        file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bacb8fe-b0c1-483c-acf5-db770d08b460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('artifacts/data_ingestion/data.zip',\n",
       " <http.client.HTTPMessage at 0x2172a2f9bd0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request \n",
    "urllib.request.urlretrieve(data_ingestion.config.source_URL, data_ingestion.config.local_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "907195a4-e9e8-4ca1-99bb-fa894384f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as: artifacts/data_ingestion/data.zip\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def download_with_curl(url, local_path):\n",
    "    try:\n",
    "        subprocess.run(['curl','-L','-o', local_path, url], check=True)\n",
    "        print(f\"File downloaded and saved as: {local_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to download file. Error: {e}\")\n",
    "\n",
    "# Example usage\n",
    "url =data_ingestion.config.source_URL\n",
    "local_path = data_ingestion.config.local_data_file\n",
    "download_with_curl(url, local_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4de462df-8f8f-4af3-93d3-d7eddc7161c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    def download_file(self):\n",
    "        if os.path.exists(self.config.local_data_file):\n",
    "            os.remove(self.config.local_data_file)\n",
    "        try:\n",
    "            subprocess.run(['curl','-L','-o', local_path, url], check=True)\n",
    "            print(f\"File downloaded and saved as: {local_path}\")\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to download file. Error: {e}\")\n",
    "        #else:\n",
    "        #    logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")      \n",
    "    #\n",
    "        #if not os.path.exists(self.config.local_data_file):\n",
    "            #user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "            #response = requests.get(self.config.source_URL,headers=user_agent)\n",
    "            #if response.status_code == 200:\n",
    "            #    with open(self.config.local_data_file, 'wb') as file:\n",
    "            #        file.write(self.config.local_data_file)\n",
    "            \n",
    "            #filename, headers = request.urlretrieve(\n",
    "            #    url = self.config.source_URL,\n",
    "            #    filename = os.path.split(data_ingestion.config.source_URL)[1]\n",
    "            #)\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac2e34-455d-4e74-be1b-ea5ccc293f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d2d4bce-5ccb-4b23-9a71-880c04b838d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-05 02:08:12,324: INFO: common: yaml file: src\\docClassify\\config\\config.yaml loaded successfully]\n",
      "[2024-02-05 02:08:12,329: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-05 02:08:12,334: INFO: common: created directory at: artifacts]\n",
      "[2024-02-05 02:08:12,337: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "File downloaded and saved as: artifacts/data_ingestion/data.zip\n",
      "[2024-02-05 02:08:16,955: INFO: 2775144944: artifacts/data_ingestion/data.zip download! with following info: \n",
      "Content-Security-Policy: font-src https://* data: ; report-uri https://www.dropbox.com/csp_log?policy_name=metaserver-whitelist ; form-action https://docs.google.com/document/fsip/ https://docs.google.com/spreadsheets/fsip/ https://docs.google.com/presentation/fsip/ https://docs.sandbox.google.com/document/fsip/ https://docs.sandbox.google.com/spreadsheets/fsip/ https://docs.sandbox.google.com/presentation/fsip/ https://*.purple.officeapps.live-int.com https://officeapps-df.live.com https://*.officeapps-df.live.com https://officeapps.live.com https://*.officeapps.live.com https://paper.dropbox.com/cloud-docs/edit 'self' https://www.dropbox.com/ https://dl-web.dropbox.com/ https://photos.dropbox.com/ https://paper.dropbox.com/ https://showcase.dropbox.com/ https://www.hellofax.com/ https://app.hellofax.com/ https://www.hellosign.com/ https://app.hellosign.com/ https://docsend.com/ https://www.docsend.com/ https://help.dropbox.com/ https://navi.dropbox.jp/ https://a.sprig.com/ https://selfguidedlearning.dropboxbusiness.com/ https://instructorledlearning.dropboxbusiness.com/ https://sales.dropboxbusiness.com/ https://accounts.google.com/ https://api.login.yahoo.com/ https://login.yahoo.com/ https://experience.dropbox.com/ https://pal-test.adyen.com https://2e83413d8036243b-Dropbox-pal-live.adyenpayments.com/ https://onedrive.live.com/picker ; default-src https://www.dropbox.com/playlist/ https://www.dropbox.com/v/s/playlist/ https://*.dropboxusercontent.com/p/hls_master_playlist/ https://*.dropboxusercontent.com/p/hls_playlist/ ; frame-ancestors 'self' ; script-src 'unsafe-eval' https://www.dropbox.com/static/api/ https://www.dropbox.com/page_success/ https://cfl.dropboxstatic.com/static/ https://www.dropboxstatic.com/static/ https://accounts.google.com/gsi/client https://canny.io/sdk.js https://www.google.com/recaptcha/ https://www.gstatic.com/recaptcha/ 'unsafe-inline' ; img-src https://* data: blob: ; object-src 'self' https://cfl.dropboxstatic.com/static/ https://www.dropboxstatic.com/static/ ; media-src https://* blob: ; worker-src https://www.dropbox.com/static/serviceworker/ https://www.dropbox.com/encrypted_folder_download/service_worker.js blob: ; connect-src https://* ws://127.0.0.1:*/ws wss://dsimports.dropbox.com/ ; frame-src https://* carousel: dbapi-6: dbapi-7: dbapi-8: dropbox-client: itms-apps: itms-appss: ; style-src https://* 'unsafe-inline' 'unsafe-eval' ; child-src https://www.dropbox.com/static/serviceworker/ blob: ; base-uri 'self'\n",
      "Content-Type: text/html; charset=utf-8\n",
      "Pragma: no-cache\n",
      "Referrer-Policy: strict-origin-when-cross-origin\n",
      "Set-Cookie: gvc=MTQwMjQ0MjgyMzQyMzEzMDgyODE1NTg5MDYwMDEzMzIyODEwNzMx; Path=/; Expires=Fri, 02 Feb 2029 23:38:56 GMT; HttpOnly; Secure; SameSite=None\n",
      "Set-Cookie: t=ipOlc4_TpnK7tjT0C1dcNQ3r; Path=/; Domain=dropbox.com; Expires=Wed, 03 Feb 2027 23:38:57 GMT; HttpOnly; Secure; SameSite=None\n",
      "Set-Cookie: __Host-js_csrf=ipOlc4_TpnK7tjT0C1dcNQ3r; Path=/; Expires=Wed, 03 Feb 2027 23:38:57 GMT; Secure; SameSite=None\n",
      "Set-Cookie: __Host-ss=NOmti6AEqQ; Path=/; Expires=Wed, 03 Feb 2027 23:38:57 GMT; HttpOnly; Secure; SameSite=Strict\n",
      "Set-Cookie: locale=en; Path=/; Domain=dropbox.com; Expires=Fri, 02 Feb 2029 23:38:57 GMT\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: SAMEORIGIN\n",
      "X-Permitted-Cross-Domain-Policies: none\n",
      "X-Robots-Tag: noindex, nofollow, noimageindex\n",
      "X-Xss-Protection: 1; mode=block\n",
      "Date: Sun, 04 Feb 2024 23:38:57 GMT\n",
      "Strict-Transport-Security: max-age=31536000; includeSubDomains\n",
      "Server: envoy\n",
      "Cache-Control: no-cache, no-store\n",
      "Vary: Accept-Encoding\n",
      "X-Dropbox-Response-Origin: far_remote\n",
      "X-Dropbox-Request-Id: 1413c9ba8d02428dac4f35055bee77a1\n",
      "Connection: close\n",
      "Transfer-Encoding: chunked\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6680fa-f4f6-4b32-b7dd-825b39a4e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5232ae2-cf7e-4e36-bd11-15a2683a60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Downloader:\n",
    "    def __init__(self, local_data_file, source_URL):\n",
    "        self.local_data_file = local_data_file\n",
    "        self.source_URL = source_URL\n",
    "\n",
    "    def download_file(self):\n",
    "        # Get the file size using curl\n",
    "        result = subprocess.run(\n",
    "            ['curl', '-sI', self.source_URL],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        headers = result.stdout\n",
    "        content_length = 0\n",
    "        for line in headers.splitlines():\n",
    "            if 'Content-Length' in line:\n",
    "                content_length = int(line.split()[-1])\n",
    "\n",
    "        if content_length == 0:\n",
    "            print(\"ERROR: Could not determine file size\")\n",
    "            return\n",
    "\n",
    "        # Download the file using curl with a progress bar\n",
    "        with tqdm(total=content_length, unit='iB', unit_scale=True) as pbar:\n",
    "            process = subprocess.Popen(\n",
    "                ['curl', '-L', '-o', self.local_data_file, self.source_URL],\n",
    "                stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=1, universal_newlines=True\n",
    "            )\n",
    "\n",
    "            for line in process.stderr:\n",
    "                if '%' in line:\n",
    "                    try:\n",
    "                        # Extract the percentage progress\n",
    "                        percentage_str = [token for token in line.split() if '%' in token]\n",
    "                        if percentage_str:\n",
    "                            progress = int(percentage_str[0].replace('%', ''))\n",
    "                            pbar.n = progress / 100 * content_length\n",
    "                            pbar.refresh()\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "\n",
    "            process.wait()\n",
    "            pbar.close()\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(\"ERROR: Download failed\")\n",
    "            return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
